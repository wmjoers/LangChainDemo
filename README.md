# LangChain demo
Det här projektet syftar till att visa upp några grundlägande APIer i LangChain och hur man kan använda det biblioteket mot både Ollama och OpenAI.

Det är skapat i Visual Studio Code med hjälp av en extension för Jupyter (note books för python) och Python 3.11.

Exempelkoden för OpenAI kräver en aktiv API-nyckel är inlagd i .env-filen.

Se "setup/Setup-OpenAI.ipynb" för att skapa -env-filen.

Exempelkoden för Ollama utgår ifrån att Ollama är installerat lokalt och lyssna på port 11434.

Se "setup/Setup-Ollama.ipynb" för exempel på hur man kan sätta upp Ollama i Docker och installera de modellerna som behövs.
